Architecturale Overview
=======================

With our platform you will be able to communicate with agricultural workers around the world helping you getting better in what you do.

Please have a look at your first release: http://jbossvertx-easyfarming.rhcloud.com/

We are maintaining a blog to keep you up to date:  http://mypredectivefarm.blogspot.co.at/

Great! We are on Google+: https://plus.google.com/u/0/communities/118045655178910862948

MyPredectiveTools uses a set of technologies that interact between them to implement these layers:

Apache Kafka: this is our data stream. Different devices will be generating messages in Kafka topics.

Schema registry - We will use Avro-schemas for Kafka topics.
REST proxy which will allow us to consume Kafka topics.
Camus, a Map-Reduce-Job to store messages from Kafka into HDFS.

HDFS: this is where our main dataset is stored.

MapReduce: This is how our batch layer recomputes batch views. Mapreduce is also used for a batch ETL process that dumps data from Kafka to HDFS.

Apache Storm: This is what we use as our speed layer. Events are consumed from Kafka and processed into “realtime views”

HBase: This is where we store the “realtime biddings” generated by Storm topologies (Publisher).

Upcoming Features
=================

 - Retina image upload via tracking.js
 - Rainfall forecast
 - Bidding platform for agricultural devices
 - Decision dashboards for buying devices
 
Predective analysis
===================

Learning lessons from our brain.

Overview - Technical layout of retinal image analysis
=====================================================

We will do it with Spark and Scala.
 

